{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from pydantic import BaseModel\n",
    "from google import genai\n",
    "from store import VectorStore \n",
    "from exa_py import Exa\n",
    "import os\n",
    "\n",
    "def get_rephraser_prompt(\n",
    "    question: str,\n",
    "    local_observations: Optional[List[str]] = [],\n",
    "    web_observations: Optional[List[str]] = [],\n",
    "    previous_queries: Optional[List[str]] = [],\n",
    ") -> str:\n",
    "    if len(local_observations)==0 and len(web_observations)==0:\n",
    "        template = f\"\"\"You are an assistant tasked with taking a natural languge query from a user\n",
    "and converting it into a query for a vectorstore. These queries are used to do deep research on a topic provided. In the process, strip out all \n",
    "information that is not relevant for the retrieval task and return a new, simplified\n",
    "question for vectorstore retrieval. Always provide the respone in the given JSON format\n",
    "\n",
    "Write the queries such that it explores different perspectives of the of topics related to the user query. Give 3 different queries.\n",
    "Here is the user query: {question}\n",
    "\n",
    "Set the done flag to False\n",
    "\"\"\"\n",
    "    else:\n",
    "        local_observations = \"\\n\".join(local_observations)            \n",
    "        if len(web_observations) > 0:\n",
    "            web_observations = \"\\n\".join(web_observations)\n",
    "            template = f\"\"\"You are an assistant tasked with taking a natural languge query from a user\n",
    "and converting it into a query for a vectorstore. In the process, strip out all \n",
    "information that is not relevant for the retrieval task and return a new, simplified\n",
    "question for vectorstore retrieval. \n",
    "\n",
    "Here is the user query that the user wants to do deep research on.\n",
    "\n",
    "User query: {question}\n",
    "\n",
    "The following information is already collected. The information within the <local_observation> tag is collected from the local documents that the user has. The infomation withing the <web_observations> tag is collected from the web. \n",
    "The previously used queries are also provided within the <previous_queries> tag. Make sure to provide more queries that explore different perspectives of the topic.  \n",
    "\n",
    "You should give more focus on the local observations and use the web observations only if needed. \n",
    "\n",
    "<previous_queries>\n",
    "{previous_queries}\n",
    "</previous_queries>\n",
    "\n",
    "<local_observations>\n",
    "{local_observations}\n",
    "</local_observations>\n",
    "\n",
    "<web observations>\n",
    "{web_observations}\n",
    "</web_observations>\n",
    "\n",
    "\n",
    "Based on this observations, you have two options:\n",
    "1. Find knowledge gaps that still need to be explored and write 3 different queries that explore different perspectives of the topic. If this is the case set the done flag to False.\n",
    "2. If there are no more knowledge gaps and you have enough information related to the topic, you dont have to provide any more queries and you can set the done flag to True. \n",
    "\n",
    "Before setting the done flag to true, make sure that the following conditions are met: \n",
    "1. You have explored different perspectives of the topic\n",
    "2. You have collected some opposing views\n",
    "3. You have collected some supporting views\n",
    "4. You have collected some views that are not directly related to the topic but can be used to explore the topic further.\n",
    "\n",
    "Always provide the respone in the given JSON format\n",
    "\n",
    "    \"\"\"\n",
    "        else:\n",
    "            template = f\"\"\"You are an assistant tasked with taking a natural languge query from a user\n",
    "and converting it into a query for a vectorstore. In the process, strip out all \n",
    "information that is not relevant for the retrieval task and return a new, simplified\n",
    "question for vectorstore retrieval. \n",
    "\n",
    "Here is the user query that the user wants to do deep research on.\n",
    "\n",
    "User query: {question}\n",
    "\n",
    "The following information is already collected. The information within the <local_observation> tag is collected from the local documents that the user has.\n",
    "The previously used queries are also provided within the <previous_queries> tag. Make sure to provide more queries that explore different perspectives of the topic.  \n",
    "\n",
    "<previous_queries>\n",
    "{previous_queries}\n",
    "</previous_queries>\n",
    "\n",
    "<local_observations>\n",
    "{local_observations}\n",
    "</local_observations>\n",
    "\n",
    "\n",
    "Based on this observations, you have two options:\n",
    "1. Find knowledge gaps that still need to be explored and write 3 different queries that explore different perspectives of the topic. If this is the case set the done flag to False.\n",
    "2. If there are no more knowledge gaps and you have enough information related to the topic, you dont have to provide any more queries and you can set the done flag to True. \n",
    "\n",
    "Before setting the done flag to true, make sure that the following conditions are met: \n",
    "1. You have explored different perspectives of the topic\n",
    "2. You have collected some opposing views\n",
    "3. You have collected some supporting views\n",
    "4. You have collected some views that are not directly related to the topic but can be used to explore the topic further.\n",
    "\n",
    "Always provide the respone in the given JSON format\n",
    "\n",
    "    \"\"\"\n",
    "    return template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client()\n",
    "\n",
    "if os.path.exists(\"doc\"):\n",
    "    my_store =  VectorStore(\"doc\")\n",
    "else:\n",
    "    os.mkdir(\"doc\")\n",
    "    my_store =  VectorStore(\"doc\")\n",
    "exa = Exa(api_key=os.environ.get(\"EXA_API_KEY\"))\n",
    "\n",
    "web_search  = False\n",
    "\n",
    "class QueryRephase(BaseModel):\n",
    "    content: str\n",
    "    querys: list[str]\n",
    "    done: bool\n",
    "\n",
    "question = \"what are the differences between SSM models and transformer models?\"\n",
    "\n",
    "\n",
    "def rephrase(prompt: str) -> list:\n",
    "    response = client.models.generate_content(\n",
    "        model='gemini-2.0-flash',\n",
    "        contents=prompt,\n",
    "        config={\n",
    "            'response_mime_type': 'application/json',\n",
    "            'response_schema': QueryRephase,\n",
    "        },\n",
    "    )\n",
    "    return response.text\n",
    "\n",
    "def query_response(prompt: str) -> QueryRephase:\n",
    "    response = rephrase(prompt)\n",
    "    my_recipes= str(response)\n",
    "    out = QueryRephase.model_validate_json(my_recipes)\n",
    "    return out\n",
    "\n",
    "def report_response(prompt: str) -> str:\n",
    "    response = client.models.generate_content(\n",
    "        model='gemini-2.0-flash',\n",
    "        contents=prompt,\n",
    "    )\n",
    "    return response.text\n",
    "\n",
    "def get_observations(queries: List[str]) -> List[str]:\n",
    "    local_observations = []\n",
    "    web_observations = []\n",
    "    for query in queries:\n",
    "        local_observation = my_store.forward(query)\n",
    "        local_observations.extend(list(local_observation))\n",
    "\n",
    "        if web_search:\n",
    "            web_result = exa.search_and_contents(query, type=\"auto\", text=True, num_results=3)\n",
    "            web_observation = []\n",
    "            for result in web_result.results:\n",
    "                observation = f\"Title: {result.title} \\n URL: {result.url} \\n Content: {result.text}\"\n",
    "                web_observation.append(observation)\n",
    "            web_observations.extend(web_observation)\n",
    "    \n",
    "    return local_observations, web_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_research(question: str, max_steps: int = 5) -> List[str]:\n",
    "    local_observations, web_observations, previous_queries = [], [], []\n",
    "    for i in range(max_steps):\n",
    "        print(\"Step Number: \", i)\n",
    "        prompt = get_rephraser_prompt(question, local_observations, web_observations, previous_queries)\n",
    "        query_responses = query_response(prompt)\n",
    "        print(\"Searching with queries: \", \"\\n\".join(query_responses.querys))\n",
    "        print(\"Done: \", query_responses.done)\n",
    "        if query_responses.done:\n",
    "            break\n",
    "        local_observation, web_observation= get_observations(query_responses.querys)\n",
    "        if len(local_observations)==0 and len(web_observations)==0:\n",
    "            local_observations = local_observation\n",
    "            web_observations = web_observation\n",
    "        else:\n",
    "            local_observations.extend(local_observation)\n",
    "            web_observations.extend(web_observation)\n",
    "    return local_observations, web_observations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step Number:  0\n",
      "Searching with queries:  What are the architectural differences between State Space Models (SSMs) and Transformer models in deep learning?\n",
      "How do SSMs and Transformers compare in terms of computational complexity, training efficiency, and memory requirements?\n",
      "In what specific applications or tasks do SSMs outperform Transformers, and vice versa, highlighting the trade-offs between the two?\n",
      "Done:  False\n",
      "Step Number:  1\n",
      "Searching with queries:  Advantages of selective state space models (SSMs) over traditional SSMs.\n",
      "How do SSMs address the computational inefficiency of Transformers on long sequences?\n",
      "What are the key weaknesses of non-selective SSMs compared to Transformers?\n",
      "Done:  False\n",
      "Step Number:  2\n",
      "Searching with queries:  \n",
      "Done:  True\n"
     ]
    }
   ],
   "source": [
    "local_observations, web_observations = do_research(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_report(question: str, local_observations: List[str], web_observations: List[str]) -> None:\n",
    "    if len(web_observations) > 0:\n",
    "        template = f\"\"\"You are an expert in writing reports. You are provided with the user query and the collected information from both local and web sources. \n",
    "The local information is within the <local_observations> tag and the web information is within the <web_observations> tag.\n",
    "\n",
    "User query: {question}\n",
    "\n",
    "<local_observations>\n",
    "{local_observations}\n",
    "</local_observations>\n",
    "\n",
    "<web_observations>\n",
    "{web_observations}\n",
    "</web_observations>\n",
    "\n",
    "Write a detailed report on the user query based on the information provided. You should provide a detailed analysis of the topic and provide a summary of the information collected from both local and web sources\n",
    "\n",
    "Instructions:\n",
    "1. Write a detailed report on the user query based on the information provided. You should provide a detailed analysis of the topic and provide a summary of the information collected from both local and web sources\n",
    "2. Format the report in a way that is easy to read and understand\n",
    "3. Do not explicitly mention if the output is from local or web observations. Just write the report as if you have all the information available.\n",
    "4. Structure the report with an introduction, body and conclusion\n",
    "5. Provide inline citations if needed. Cite the file name for the local observations and the URL for the web observations. Provide all references at the end of the report.\n",
    "6. Provide tables if needed to show differences\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    if len(web_observations) == 0:\n",
    "        template = f\"\"\"You are an expert in writing reports. You are provided with the user query and the collected information from local sources. \n",
    "The local information is within the <local_observations> tag.\n",
    "\n",
    "User query: {question}\n",
    "\n",
    "<local_observations>\n",
    "{local_observations}\n",
    "</local_observations>\n",
    "\n",
    "Instructions:\n",
    "1. Write a detailed report on the user query based on the information provided. You should provide a detailed analysis of the topic and provide a summary of the information collected from both local and web sources\n",
    "2. Format the report in a way that is easy to read and understand\n",
    "3. Do not explicitly mention if the output is from local or web observations. Just write the report as if you have all the information available.\n",
    "4. Structure the report with an introduction, body and conclusion\n",
    "5. Provide inline citations if needed. Cite the file name. Provide all references as file name at the end of the report.\n",
    "6. Provide tables if needed to show differences\n",
    "        \"\"\"\n",
    "\n",
    "    response = report_response(template)\n",
    "    return response\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = write_report(question, local_observations, web_observations)\n",
    "\n",
    "with open(\"report.md\", \"w\") as f:\n",
    "    f.write(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
